{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query tweets\n",
    "Load in tweets to MongoDB database  \n",
    "*First start MongoDB service:*  \n",
    "`mongod --config /usr/local/etc/mongod.conf`  \n",
    "`brew services start mongodb-community`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dependencies\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import ConnectionFailure\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# Location MongoDB:\n",
    "mongo_host = None\n",
    "# Name collection\n",
    "client_name = \"fundamentals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create connection\n",
    "try:\n",
    "    client = MongoClient(mongo_host)\n",
    "    client.admin.command('ismaster')\n",
    "    db = client[client_name] \n",
    "    twitter_db = db.twitter\n",
    "    \n",
    "except ConnectionFailure:\n",
    "    print(\"Connection to MongoDB server could not be established\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of tweets: 657307\n"
     ]
    }
   ],
   "source": [
    "# Test connection by counting\n",
    "print(\"Amount of tweets:\",twitter_db.count_documents({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in state election data\n",
    "state_counts = pd.read_csv('../datasets/1976-2016-president.csv')\n",
    "\n",
    "# Filter for 2016 election and the two major candidates\n",
    "candidates = ['Clinton, Hillary', 'Trump, Donald J.']\n",
    "state_2016 = state_counts[(state_counts[\"year\"] == 2016)& \n",
    "                          (state_counts[\"candidate\"].isin(candidates))]\n",
    "\n",
    "# Sum candidate votes across multiple party names\n",
    "state_candidates = state_2016[[\"state\",\"candidate\",\"candidatevotes\"]].groupby(\n",
    "    [\"state\",\"candidate\"], as_index = True).sum()\n",
    "\n",
    "# Create dataframe with relevant colums and merge with votecount\n",
    "state_totals = state_2016[[\"state\",\"state_po\",\"candidate\",\"totalvotes\"]].drop_duplicates(\n",
    "    subset=[\"state\",\"candidate\"])\n",
    "election_totals = pd.merge(state_totals ,state_candidates, how = \"right\", \n",
    "                           on = [\"state\", \"candidate\"] )\n",
    "election_totals[\"candidate_percent\"] = election_totals[\"candidatevotes\"] / election_totals[\"totalvotes\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract state name\n",
    "# Create dataframe of state names\n",
    "state_names = state_2016[[\"state\",\"state_po\"]].drop_duplicates().reset_index(drop=True)\n",
    "state_names.to_pickle(\"../datasets/state_names.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_names_test(state_db, print_errors = False, loc_state_names: \"../datasets/state_names.pkl\"):\n",
    "    state_names = pd.read_pickle(loc_state_names)\n",
    "    n_errors = 0\n",
    "    full_name_errors = dict()\n",
    "    error_names = dict()\n",
    "    n_correct = 0\n",
    "    for obj in state_db:\n",
    "        # Regex on last letters in place name and match to state\n",
    "        state_short = re.findall(\", ([A-Z]{2})$\",obj[\"place\"]['full_name'])\n",
    "        if len(state_short) == 1:\n",
    "            state_short = state_short[0]\n",
    "            state_full = state_names[state_names[\"state_po\"] == state_short].values[0,0]\n",
    "            n_correct += 1\n",
    "        # If no patten found search for state, USA    \n",
    "        elif len(state_short) == 0:\n",
    "            state_full = re.findall(\"([A-Za-z ]*\\w+), USA$\",obj[\"place\"]['full_name'])\n",
    "            if len(state_full) == 0:\n",
    "                n_errors += 1\n",
    "                error_empty = obj[\"place\"]['full_name']\n",
    "                if error_empty not in full_name_errors.keys():\n",
    "                    full_name_errors[error_empty] = 1\n",
    "                else:\n",
    "                    full_name_errors[error_empty] = full_name_errors[error_empty] + 1\n",
    "                continue\n",
    "            elif len(state_full) == 1:\n",
    "                state_full = state_full[0]\n",
    "                try:\n",
    "                    state_short = state_names[state_names[\"state\"] == state_full].values[0,1]\n",
    "                    n_correct += 1\n",
    "                except:\n",
    "                    error_value = obj[\"place\"]['full_name']\n",
    "                    n_errors += 1\n",
    "                    if error_value not in error_names.keys():\n",
    "                        error_names[error_value] = 1\n",
    "                    else:\n",
    "                        error_names[error_value] = error_names[error_value] + 1\n",
    "                    continue\n",
    "            else: print(obj[\"place\"]['full_name'])\n",
    "        if state_short == None:\n",
    "            print(obj[\"place\"]['full_name'], state_short, state_full)\n",
    "    print(\"Correct: \", n_correct)\n",
    "    print(\"Errors: \",n_errors)\n",
    "    if print_errors:\n",
    "        print(\"Full name\")\n",
    "        for name, value in full_name_errors.items():\n",
    "            print(name,\": \",value)\n",
    "        print(\"Lookup\")\n",
    "        for name, value in error_names.items():\n",
    "            print(name,\": \",value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  587414\n",
      "Errors:  5854\n"
     ]
    }
   ],
   "source": [
    "# Test how many errors:\n",
    "city_state = twitter_db.find(filter = {\"place.country_code\" : \"US\"}, projection = \n",
    "                           { \"_id\": 0 , \"place.full_name\": 1}, limit = 0)\n",
    "state_names_test(city_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less than 1% errors, not adding extra exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_names_json(state_json, print_errors = False\n",
    "                     , loc_state_names: \"../datasets/state_names.pkl\"):\n",
    "    state_names = pd.read_pickle(loc_state_names)\n",
    "    tweet_list = list()\n",
    "    n_errors = 0\n",
    "    full_name_errors = dict()\n",
    "    error_names = dict()\n",
    "    n_correct = 0\n",
    "    for obj in state_json:\n",
    "        # Regex on last letters in place name and match to state\n",
    "        state_short = re.findall(\", ([A-Z]{2})$\",obj[\"place\"]['full_name'])\n",
    "        if len(state_short) == 1:\n",
    "            state_short = state_short[0]\n",
    "            # Match abreviation with full state name\n",
    "            state_full = state_names[state_names[\"state_po\"] == state_short].values[0,0]\n",
    "            n_correct += 1\n",
    "        # If no patten found search for state, USA    \n",
    "        elif len(state_short) == 0:\n",
    "            state_full = re.findall(\"([A-Za-z ]*\\w+), USA$\",obj[\"place\"]['full_name'])\n",
    "            if len(state_full) == 0:\n",
    "                n_errors += 1\n",
    "                error_empty = obj[\"place\"]['full_name']\n",
    "                if error_empty not in full_name_errors.keys():\n",
    "                    full_name_errors[error_empty] = 1\n",
    "                else:\n",
    "                    full_name_errors[error_empty] = full_name_errors[error_empty] + 1\n",
    "                continue\n",
    "            elif len(state_full) == 1:\n",
    "                state_full = state_full[0]\n",
    "                if sum(state_names[\"state\"] == state_full) > 0:\n",
    "                    # Match full state name with abreviation\n",
    "                    state_short = state_names[state_names[\"state\"] == state_full].values[0,1]\n",
    "                    n_correct += 1\n",
    "                else:\n",
    "                    error_value = obj[\"place\"]['full_name']\n",
    "                    n_errors += 1\n",
    "                    if error_value not in error_names.keys():\n",
    "                        error_names[error_value] = 1\n",
    "                    else:\n",
    "                        error_names[error_value] = error_names[error_value] + 1\n",
    "                    continue\n",
    "            else: print(obj[\"place\"]['full_name'])\n",
    "        # Add state values to tweet and append to results\n",
    "        \n",
    "        obj[\"place\"][\"state_short\"] = state_short\n",
    "        obj[\"place\"][\"state_full\"] = state_full\n",
    "        tweet_list.append(obj)\n",
    "    print(\"Correct: \", n_correct)\n",
    "    print(\"Errors: \",n_errors)\n",
    "    if print_errors:\n",
    "        print(\"Full name\")\n",
    "        for name, value in full_name_errors.items():\n",
    "            print(name,\": \",value)\n",
    "        print(\"Lookup\")\n",
    "        for name, value in error_names.items():\n",
    "            print(name,\": \",value)\n",
    "    return(tweet_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  498\n",
      "Errors:  2\n"
     ]
    }
   ],
   "source": [
    "# Example json list function:\n",
    "\n",
    "city_state = twitter_db.find(filter = {\"place.country_code\" : \"US\"}, projection = \n",
    "                           { \"_id\": 0 , \"text\": 1, \"place.full_name\": 1}, limit = 500)\n",
    "test_json = state_names_json(city_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_names_df(state_df, location_place = \"place\", dic_extracted = False,\n",
    "                   print_errors = False, loc_state_names: \"../datasets/state_names.pkl\"):\n",
    "    \"\"\"\n",
    "    Transforms the tweet locations to states values via regex lookup.\n",
    "    Make sure state_names DataFrame is loaded.\n",
    "    location_place: name of place column\n",
    "    dic_extracted: Is the place value extracted from the dictionairy within the dataframe?\n",
    "    print_errors: Print errors values\n",
    "    \"\"\"\n",
    "    state_names = pd.read_pickle(loc_state_names)\n",
    "    state_df[\"state_short\"] = None\n",
    "    state_df[\"state_full\"] = None\n",
    "    n_errors = 0\n",
    "    full_name_errors = dict()\n",
    "    error_names = dict()\n",
    "    n_correct = 0\n",
    "    for row in state_df.itertuples():\n",
    "        # Regex on last letters in place name and match to state\n",
    "        if dic_extracted:\n",
    "            state_short = re.findall(\", ([A-Z]{2})$\",getattr(row,location_place))\n",
    "        else:\n",
    "            state_short = re.findall(\", ([A-Z]{2})$\",getattr(row,location_place)['full_name'])\n",
    "        \n",
    "        if len(state_short) == 1:\n",
    "            state_short = state_short[0]\n",
    "            # Match abreviation with full state name\n",
    "            state_full = state_names[state_names[\"state_po\"] == state_short].values[0,0]\n",
    "            n_correct += 1\n",
    "\n",
    "        # If no patten found search for state, USA    \n",
    "        elif len(state_short) == 0:\n",
    "            if dic_extracted:\n",
    "                state_full = re.findall(\"([A-Za-z ]*\\w+), USA$\",getattr(row,location_place))\n",
    "            else:\n",
    "                state_full = re.findall(\"([A-Za-z ]*\\w+), USA$\",\n",
    "                                        getattr(row,location_place)['full_name'])\n",
    "            if len(state_full) == 0:\n",
    "                n_errors += 1\n",
    "                if dic_extracted:\n",
    "                    error_empty = getattr(row,location_place)\n",
    "                else:\n",
    "                    error_empty = getattr(row,location_place)['full_name']\n",
    "                if error_empty not in full_name_errors.keys():\n",
    "                    full_name_errors[error_empty] = 1\n",
    "                else:\n",
    "                    full_name_errors[error_empty] = full_name_errors[error_empty] + 1\n",
    "                continue\n",
    "            elif len(state_full) == 1:\n",
    "                state_full = state_full[0]\n",
    "                if sum(state_names[\"state\"] == state_full) > 0:\n",
    "                    # Match full state name with abreviation\n",
    "                    state_short = state_names[state_names[\"state\"] == state_full].values[0,1]\n",
    "                    n_correct += 1\n",
    "                else:\n",
    "                    if dic_extracted:\n",
    "                        error_value = getattr(row,location_place)\n",
    "                    else:\n",
    "                        error_value = getattr(row,location_place)['full_name']\n",
    "                    n_errors += 1\n",
    "                    if error_value not in error_names.keys():\n",
    "                        error_names[error_value] = 1\n",
    "                    else:\n",
    "                        error_names[error_value] = error_names[error_value] + 1\n",
    "                    continue\n",
    "            else: print(\"Error: \",getattr(row,location_place))\n",
    "        # Add state values to correct column and append to results\n",
    "        state_df.at[row[0], \"state_short\"] = state_short\n",
    "        state_df.at[row[0], \"state_full\"] = state_full\n",
    "    print(\"Correct: \", n_correct)\n",
    "    print(\"Errors: \",n_errors)\n",
    "    if print_errors:\n",
    "        print(\"Full name\")\n",
    "        for name, value in full_name_errors.items():\n",
    "            print(name,\": \",value)\n",
    "        print(\"Lookup\")\n",
    "        for name, value in error_names.items():\n",
    "            print(name,\": \",value)\n",
    "    return(state_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:  993\n",
      "Errors:  7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>place</th>\n",
       "      <th>state_short</th>\n",
       "      <th>state_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@theblaze @realDonaldTrump https://t.co/TY9DlZ...</td>\n",
       "      <td>{'full_name': 'Frontenac, MO', 'country_code':...</td>\n",
       "      <td>MO</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@BarackObama \\n@FBI\\n@LORETTALYNCH \\nALL IN CO...</td>\n",
       "      <td>{'full_name': 'Baton Rouge, LA', 'country_code...</td>\n",
       "      <td>LA</td>\n",
       "      <td>Louisiana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@theblaze @realDonaldTrump https://t.co/n050DB...</td>\n",
       "      <td>{'full_name': 'Frontenac, MO', 'country_code':...</td>\n",
       "      <td>MO</td>\n",
       "      <td>Missouri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>#CNN #newday clear #Trump deliberately throwin...</td>\n",
       "      <td>{'full_name': 'Baltimore, MD', 'country_code':...</td>\n",
       "      <td>MD</td>\n",
       "      <td>Maryland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@realDonaldTrump, you wouldn't recognize a lie...</td>\n",
       "      <td>{'full_name': 'Palm Springs, CA', 'country_cod...</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>@realDonaldTrump You Sir are a mental case !\\n...</td>\n",
       "      <td>{'full_name': 'Doylestown, PA', 'country_code'...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Pennsylvania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>#inequality is not #democracy,its man made by ...</td>\n",
       "      <td>{'full_name': 'New Jersey, USA', 'country_code...</td>\n",
       "      <td>NJ</td>\n",
       "      <td>New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>@realDonaldTrump The president of #isis says y...</td>\n",
       "      <td>{'full_name': 'Indio, CA', 'country_code': 'US'}</td>\n",
       "      <td>CA</td>\n",
       "      <td>California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>@sethmoulton Stop trying to DEFEND the INDEFEN...</td>\n",
       "      <td>{'full_name': 'New Jersey, USA', 'country_code...</td>\n",
       "      <td>NJ</td>\n",
       "      <td>New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>@wolfblitzer Sorry but you looked gullible &amp;am...</td>\n",
       "      <td>{'full_name': 'Bryn Mawr, PA', 'country_code':...</td>\n",
       "      <td>PA</td>\n",
       "      <td>Pennsylvania</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "0    @theblaze @realDonaldTrump https://t.co/TY9DlZ...   \n",
       "1    @BarackObama \\n@FBI\\n@LORETTALYNCH \\nALL IN CO...   \n",
       "2    @theblaze @realDonaldTrump https://t.co/n050DB...   \n",
       "3    #CNN #newday clear #Trump deliberately throwin...   \n",
       "4    @realDonaldTrump, you wouldn't recognize a lie...   \n",
       "..                                                 ...   \n",
       "995  @realDonaldTrump You Sir are a mental case !\\n...   \n",
       "996  #inequality is not #democracy,its man made by ...   \n",
       "997  @realDonaldTrump The president of #isis says y...   \n",
       "998  @sethmoulton Stop trying to DEFEND the INDEFEN...   \n",
       "999  @wolfblitzer Sorry but you looked gullible &am...   \n",
       "\n",
       "                                                 place state_short  \\\n",
       "0    {'full_name': 'Frontenac, MO', 'country_code':...          MO   \n",
       "1    {'full_name': 'Baton Rouge, LA', 'country_code...          LA   \n",
       "2    {'full_name': 'Frontenac, MO', 'country_code':...          MO   \n",
       "3    {'full_name': 'Baltimore, MD', 'country_code':...          MD   \n",
       "4    {'full_name': 'Palm Springs, CA', 'country_cod...          CA   \n",
       "..                                                 ...         ...   \n",
       "995  {'full_name': 'Doylestown, PA', 'country_code'...          PA   \n",
       "996  {'full_name': 'New Jersey, USA', 'country_code...          NJ   \n",
       "997   {'full_name': 'Indio, CA', 'country_code': 'US'}          CA   \n",
       "998  {'full_name': 'New Jersey, USA', 'country_code...          NJ   \n",
       "999  {'full_name': 'Bryn Mawr, PA', 'country_code':...          PA   \n",
       "\n",
       "       state_full  \n",
       "0        Missouri  \n",
       "1       Louisiana  \n",
       "2        Missouri  \n",
       "3        Maryland  \n",
       "4      California  \n",
       "..            ...  \n",
       "995  Pennsylvania  \n",
       "996    New Jersey  \n",
       "997    California  \n",
       "998    New Jersey  \n",
       "999  Pennsylvania  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example df function:\n",
    "city_state = twitter_db.find(filter = {\"place.country_code\" : \"US\"}, projection = \n",
    "                           { \"_id\": 0 , \"text\": 1, \"place.full_name\": 1, \n",
    "                            \"place.country_code\" :1}, limit = 1000)\n",
    "example_df = pd.DataFrame(city_state)\n",
    "# example_df[\"test\"] = None\n",
    "# for row in example_df.itertuples():\n",
    "#     example_df.at[row[0], \"test\"] = getattr(row,\"place\")['full_name']\n",
    "test_example_df = state_names_df(example_df)\n",
    "display(test_example_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>place</th>\n",
       "      <th>state_short</th>\n",
       "      <th>state_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>408</td>\n",
       "      <td>@magnifier661 @SallyAu81783497 @HillaryClinton...</td>\n",
       "      <td>{'full_name': 'Tumon, USA', 'country_code': 'US'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>@magnifier661 @SallyAu81783497 @HillaryClinton...</td>\n",
       "      <td>{'full_name': 'Tumon, USA', 'country_code': 'US'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>525</td>\n",
       "      <td>@realDonaldTrump is definitely going to beat O...</td>\n",
       "      <td>{'full_name': 'Allendale, Austin', 'country_co...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>577</td>\n",
       "      <td>@Dollfinish @realDonaldTrump @EnemyWithinn @el...</td>\n",
       "      <td>{'full_name': 'Tumon, USA', 'country_code': 'US'}</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>589</td>\n",
       "      <td>@realDonaldTrump \"Trump acknowledges he could ...</td>\n",
       "      <td>{'full_name': 'Estados Unidos', 'country_code'...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  \\\n",
       "408  @magnifier661 @SallyAu81783497 @HillaryClinton...   \n",
       "460  @magnifier661 @SallyAu81783497 @HillaryClinton...   \n",
       "525  @realDonaldTrump is definitely going to beat O...   \n",
       "577  @Dollfinish @realDonaldTrump @EnemyWithinn @el...   \n",
       "589  @realDonaldTrump \"Trump acknowledges he could ...   \n",
       "\n",
       "                                                 place state_short state_full  \n",
       "408  {'full_name': 'Tumon, USA', 'country_code': 'US'}        None       None  \n",
       "460  {'full_name': 'Tumon, USA', 'country_code': 'US'}        None       None  \n",
       "525  {'full_name': 'Allendale, Austin', 'country_co...        None       None  \n",
       "577  {'full_name': 'Tumon, USA', 'country_code': 'US'}        None       None  \n",
       "589  {'full_name': 'Estados Unidos', 'country_code'...        None       None  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_example_df[test_example_df[\"state_full\"].isna()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of US country tweets 593268\n"
     ]
    }
   ],
   "source": [
    "# Create pickle of DataFrame of all us tweets with added state locations\n",
    "print(\"Number of US country tweets\", twitter_db.count_documents(filter = \n",
    " {\"place.country_code\" : \"US\"}))\n",
    "total_df = pd.DataFrame(twitter_db.find(filter = {\"place.country_code\" : \"US\"}, limit = 0))\n",
    "\n",
    "total_df.to_pickle(\"dataset/state_tweet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: Alabama, Matched: 8194, Modified: 0\n",
      "State: Alaska, Matched: 1399, Modified: 0\n",
      "State: Arizona, Matched: 17687, Modified: 0\n",
      "State: Arkansas, Matched: 3293, Modified: 0\n",
      "State: California, Matched: 72446, Modified: 0\n",
      "State: Colorado, Matched: 9511, Modified: 0\n",
      "State: Connecticut, Matched: 5075, Modified: 0\n",
      "State: Delaware, Matched: 1606, Modified: 0\n",
      "State: District of Columbia, Matched: 4452, Modified: 0\n",
      "State: Florida, Matched: 57823, Modified: 0\n",
      "State: Georgia, Matched: 19105, Modified: 0\n",
      "State: Hawaii, Matched: 2773, Modified: 0\n",
      "State: Idaho, Matched: 1955, Modified: 0\n",
      "State: Illinois, Matched: 22042, Modified: 0\n",
      "State: Indiana, Matched: 7486, Modified: 0\n",
      "State: Iowa, Matched: 4280, Modified: 0\n",
      "State: Kansas, Matched: 3434, Modified: 0\n",
      "State: Kentucky, Matched: 12200, Modified: 0\n",
      "State: Louisiana, Matched: 9852, Modified: 0\n",
      "State: Maine, Matched: 4469, Modified: 0\n",
      "State: Maryland, Matched: 11109, Modified: 0\n",
      "State: Massachusetts, Matched: 13388, Modified: 0\n",
      "State: Michigan, Matched: 11889, Modified: 0\n",
      "State: Minnesota, Matched: 4388, Modified: 0\n",
      "State: Mississippi, Matched: 5168, Modified: 0\n",
      "State: Missouri, Matched: 8493, Modified: 0\n",
      "State: Montana, Matched: 623, Modified: 0\n",
      "State: Nebraska, Matched: 1981, Modified: 0\n",
      "State: Nevada, Matched: 8098, Modified: 0\n",
      "State: New Hampshire, Matched: 3351, Modified: 0\n",
      "State: New Jersey, Matched: 20591, Modified: 0\n",
      "State: New Mexico, Matched: 2934, Modified: 0\n",
      "State: New York, Matched: 49469, Modified: 0\n",
      "State: North Carolina, Matched: 17275, Modified: 0\n",
      "State: North Dakota, Matched: 422, Modified: 0\n",
      "State: Ohio, Matched: 16910, Modified: 0\n",
      "State: Oklahoma, Matched: 4742, Modified: 0\n",
      "State: Oregon, Matched: 7728, Modified: 0\n",
      "State: Pennsylvania, Matched: 26444, Modified: 0\n",
      "State: Rhode Island, Matched: 2180, Modified: 0\n",
      "State: South Carolina, Matched: 6830, Modified: 0\n",
      "State: South Dakota, Matched: 489, Modified: 0\n",
      "State: Tennessee, Matched: 9554, Modified: 0\n",
      "State: Texas, Matched: 41655, Modified: 0\n",
      "State: Utah, Matched: 2526, Modified: 0\n",
      "State: Vermont, Matched: 921, Modified: 0\n",
      "State: Virginia, Matched: 16061, Modified: 486\n",
      "State: Washington, Matched: 13266, Modified: 0\n",
      "State: West Virginia, Matched: 1556, Modified: 486\n",
      "State: Wisconsin, Matched: 8160, Modified: 0\n",
      "State: Wyoming, Matched: 617, Modified: 0\n"
     ]
    }
   ],
   "source": [
    "# MongoDB pipeline\n",
    "# Run once to set database\n",
    "state_names = pd.read_pickle(\"../datasets/state_names.pkl\")\n",
    "for state in state_names.itertuples():\n",
    "    result = twitter_db.update_many(filter = {\"$and\" : [{\"place.country_code\" : \"US\"},\n",
    "                {\"$or\": [{\"place.full_name\" : {\"$regex\" :\", \"+state.state_po+\"$\"}},\n",
    "                         {\"place.full_name\" : {\"$regex\" :state.state+\", USA$\"}}\n",
    "                                    ]}]},\n",
    "                          update = {\"$set\": { \"place.state\" : state.state }})\n",
    "    print(\"State: \"+state.state+\", Matched: \"+str(result.matched_count)+\", Modified: \"+ \n",
    "          str(result.modified_count))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "587414\n"
     ]
    }
   ],
   "source": [
    "print(twitter_db.count_documents({ \"place.state\":{\"$exists\" : True} }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example MongoDB queries\n",
    "# Distinct languages\n",
    "twitter_db.distinct(\"lang\")\n",
    "\n",
    "# Extract data form bounding box\n",
    "location = twitter_db.find(filter = {\"place.country_code\" : \"US\"}, projection = \n",
    "                           { \"_id\": 0 , \"place.bounding_box.coordinates\": 1}, limit = 5)\n",
    "for obj in location:\n",
    "    print(obj[\"place\"]['bounding_box']['coordinates'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
