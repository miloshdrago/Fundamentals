{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to perform simple count analysis of hashtags and @ mentions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question: *Can a sentiment analysis of tweets addressed to the major candidates predict an election result in a state?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*H0: There **is NO** relationship between the sentiment of tweets addressed to the major candidates and the state outcome of the election.*\n",
    "\n",
    "*H1: There **is** a relationship between the sentiment of tweets addressed to the major candidates and the state outcome of the election.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data inputting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import collections\n",
    "from collections import Counter\n",
    "from textblob import TextBlob \n",
    "import timeit as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import csv\n",
    "tweets = pd.read_csv(\"tweets_per_user.csv\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>418</td>\n",
       "      <td>['@tristanwalker @realDonaldTrump I appreciate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>521</td>\n",
       "      <td>['@realDonaldTrump where can I buy one of thes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>747</td>\n",
       "      <td>[\"@cindylwarner1 in all fairness, we've always...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>997</td>\n",
       "      <td>['@BaldGuyGreeting @realDonaldTrump Gosh I tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1135</td>\n",
       "      <td>[\"Unless your friend is @realDonaldTrump, I ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user                                              tweet\n",
       "0   418  ['@tristanwalker @realDonaldTrump I appreciate...\n",
       "1   521  ['@realDonaldTrump where can I buy one of thes...\n",
       "2   747  [\"@cindylwarner1 in all fairness, we've always...\n",
       "3   997  ['@BaldGuyGreeting @realDonaldTrump Gosh I tho...\n",
       "4  1135  [\"Unless your friend is @realDonaldTrump, I ha..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Name DataFrame columns\n",
    "tweets.columns = [\"user\",\"tweet\"]\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets: 86421\n"
     ]
    }
   ],
   "source": [
    "# Check the number of tweets\n",
    "tweet_column = tweets[\"tweet\"]\n",
    "print(\"Number of tweets:\",len(tweet_column))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Hashtag metrics\n",
    "\n",
    "#### We analyse the count of hashtags to see which of the two candidates is the most trending candidate and wether the mentions are mostly positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in list: 86421\n",
      "Number of hashtag users: 37648\n",
      "Number of total hashtags: 558949\n"
     ]
    }
   ],
   "source": [
    "# Create a list of lists with hashtags\n",
    "tweet_list = []\n",
    "for i in range(0,len(tweet_column)):\n",
    "    tweet_list.append(tweet_column[i])\n",
    "\n",
    "# Create a list of lists with hashtags\n",
    "hashtags = []\n",
    "for i in range(0,len(tweet_list)):\n",
    "    pat = re.compile(r\"#(\\w+)\")\n",
    "    hashtags.append(pat.findall(tweet_list[i]))\n",
    "\n",
    "# Check that the number of list elements is the same as the number of users\n",
    "print(\"Number of elements in list:\",len(hashtags))\n",
    "\n",
    "# Remover users which do not use hashtags\n",
    "hashtags = [x for x in hashtags if x != []]\n",
    "print(\"Number of hashtag users:\",len(hashtags))\n",
    "\n",
    "# Flatten the list of lists and see how many total hashtags\n",
    "hashtags_flat_list = [item for sublist in hashtags for item in sublist]\n",
    "print(\"Number of total hashtags:\",len(hashtags_flat_list))\n",
    "\n",
    "# Lowercase the hashtags so there is no difference anymore (Trump=trump)\n",
    "hashtags_flat_list_lower = [x.lower() for x in hashtags_flat_list]\n",
    "\n",
    "# Add an hashtag to the start of every word\n",
    "hashtags_flat_list_lower = [\"#\" + hashtag for hashtag in hashtags_flat_list_lower]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most popular hashtag was **#trump** which is just a general hashtag which does not have a positive or negative connotation. \n",
    "\n",
    "We see that **#trump** was more popular than **#hillary** and **#hillaryclinton** combined.\n",
    "\n",
    "It is interesting to note that although #nevertrump is the second most mentioned hashtag, **#maga** is still is more popular than **#imwithher** which supports the claim that Trump was the most trending candidate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. @ mentions metrics\n",
    "\n",
    "We analyse the count of @ mentions to see which of the two candidates is the most trending candidate and wether the mentions are mostly positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in list: 86421\n",
      "Number of @ mentions users: 68785\n",
      "Number of total @ mentions: 1131258\n"
     ]
    }
   ],
   "source": [
    "# Create a list of lists with @\n",
    "ats = []\n",
    "for i in range(0,len(tweet_list)):\n",
    "    pat = re.compile(r\"@(\\w+)\")\n",
    "    ats.append(pat.findall(tweet_list[i]))\n",
    "\n",
    "# Check that the number of list elements is the same as the number of users\n",
    "# 86421 tweets when ranked by user\n",
    "print(\"Number of elements in list:\",len(ats))\n",
    "\n",
    "# Remover users which do not use @\n",
    "ats = [x for x in ats if x != []]\n",
    "print(\"Number of @ mentions users:\",len(ats))\n",
    "\n",
    "# Flatten the list of lists and see how many total @\n",
    "ats_flat_list = [item for sublist in ats for item in sublist]\n",
    "print(\"Number of total @ mentions:\",len(ats_flat_list))\n",
    "\n",
    "# Lowercase the @ so there is no difference anymore (@realDonaldTrump = @realdonaldtrump )\n",
    "ats_flat_list_lower = [x.lower() for x in ats_flat_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and rank the top 20 most popular @ mentions\n",
    "ats_counter = Counter(ats_flat_list_lower)\n",
    "ats_top_20 = ats_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of top 20 @ mentions\n",
    "ats_df = pd.DataFrame(ats_top_20)\n",
    "ats_df.columns=[\"@ mentions\",\"Count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most popular @ mention was **@realdonaldtrump** which refers to Trumpâ€™s Twitter account. **@realdonaldtrump** was mentioned twice more than **@hillaryclinton** which again support the claim that Trump was a more interesting candidate. \n",
    "\n",
    "The pro-Trump news channel **@foxnews** was mentioned more than the anti-Trump media source **@cnn**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through the use of metrics such as count of hashtags and @ mentions we can conclude that Trump was indeed the most talked about candidate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hashtag Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find a way to separate the hashtags which contain multiple words eg. \"nevertrump\" = \"never trump\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count and rank the top #### most popular hashtags mentions\n",
    "hashtags_counter = Counter(hashtags_flat_list_lower).\n",
    "hashtag_rank = hashtags_counter.most_common(558949)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Hashtag  Count\n",
      "0           #trump  57406\n",
      "1      #nevertrump  21275\n",
      "2            #maga  18935\n",
      "3       #imwithher  17932\n",
      "4    #neverhillary  14662\n",
      "5         #hillary  13835\n",
      "6  #hillaryclinton  13430\n",
      "7    #trumppence16  13362\n",
      "8     #donaldtrump  12344\n",
      "9  #crookedhillary  11414\n",
      "\n",
      "lenght of DataFrame: 49829\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe and a list of ranked hashtags.\n",
    "hashtag_df = pd.DataFrame(hashtag_rank)\n",
    "hashtag_df.columns=[\"Hashtag\",\"Count\"]\n",
    "print(hashtag_df.head(10))\n",
    "print()\n",
    "print(\"lenght of DataFrame:\",len(hashtag_df))\n",
    "hashtag_raw_count = hashtag_df[\"Count\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the functions used to separate the words in a hashtag.\n",
    "\n",
    "def initialize_words():\n",
    "    \"\"\"\n",
    "    Initialize word function by opening a file containing common english words.\n",
    "    \"\"\"\n",
    "    content = None\n",
    "    with open('wordlist.txt') as f: \n",
    "        content = f.readlines()\n",
    "        \n",
    "    return [word.rstrip('\\n') for word in content]\n",
    "\n",
    "\n",
    "def parse_sentence(sentence, wordlist):\n",
    "    \"\"\"\n",
    "    Parse sentences and look for hashtags.\n",
    "    If first term of words is an hashtag, parse it, else we append the word.\n",
    "    \"\"\"\n",
    "    new_sentence = \"\"    \n",
    "    terms = sentence.split(' ')    \n",
    "    for term in terms:\n",
    "        if term[0] == '#': \n",
    "            new_sentence += parse_tag(term, wordlist)\n",
    "        else: \n",
    "            new_sentence += term\n",
    "        new_sentence += \" \"\n",
    "\n",
    "    return new_sentence \n",
    "\n",
    "\n",
    "def parse_tag(term, wordlist):\n",
    "    \"\"\"\n",
    "    Remove hashtag, split by dash.\n",
    "    Be careful for the special case where the length of tag is equal to length of word.\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    tags = term[1:].split('-')\n",
    "    for tag in tags:\n",
    "        word = find_word(tag, wordlist)    \n",
    "        while word != None and len(tag) > 0:\n",
    "            words.append(word)   \n",
    "            if len(tag) == len(word): \n",
    "                break\n",
    "            tag = tag[len(word):]\n",
    "            word = find_word(tag, wordlist)\n",
    "            \n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def find_word(token, wordlist):\n",
    "    \"\"\"\n",
    "    Find hashtag in wordlist.\n",
    "    \"\"\"\n",
    "    i = len(token) + 1\n",
    "    while i > 1:\n",
    "        i -= 1\n",
    "        if token[:i] in wordlist:\n",
    "            return token[:i]\n",
    "        \n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run step 1:  115.0454066\n",
      "Time to run step 2:  268.83435349999996\n",
      "Time to run step 3:  467.1204337\n",
      "Time to run step 4:  660.5423647\n",
      "Time to run:  880.3862531000001\n"
     ]
    }
   ],
   "source": [
    "# Separate the hashtags so \"nevertrump\" becomes \"never trump\"\n",
    "# This is an extremely inneficient way of separating the hashtags, if you try to do a single for-loop the script never ends.\n",
    "# Please feel free to adapt this for better efficiency\n",
    "\n",
    "# Start timer to see program-run time\n",
    "start = time.default_timer()\n",
    "wordlist = initialize_words()\n",
    "list_10000 = []\n",
    "for i in range (0,10000):\n",
    "    sentence = hashtag_df[\"Hashtag\"][i]\n",
    "    clean_hashtag=parse_sentence(sentence, wordlist)\n",
    "    list_10000.append(clean_hashtag)\n",
    "\n",
    "stop = time.default_timer()\n",
    "print('Time to run step 1: ', stop - start)\n",
    "\n",
    "list_20000 = []\n",
    "for i in range(10000,20000):\n",
    "    sentence = hashtag_df[\"Hashtag\"][i]\n",
    "    clean_hashtag = parse_sentence(sentence, wordlist)\n",
    "    list_20000.append(clean_hashtag)\n",
    "\n",
    "stop = time.default_timer()\n",
    "print('Time to run step 2: ', stop - start)\n",
    "\n",
    "list_30000 = []\n",
    "for i in range(20000,30000):\n",
    "    sentence = hashtag_df[\"Hashtag\"][i]\n",
    "    clean_hashtag = parse_sentence(sentence, wordlist)\n",
    "    list_30000.append(clean_hashtag)\n",
    "\n",
    "stop = time.default_timer()\n",
    "print('Time to run step 3: ', stop - start)    \n",
    "\n",
    "list_40000 = []\n",
    "for i in range(30000,40000):\n",
    "    sentence = hashtag_df[\"Hashtag\"][i]\n",
    "    clean_hashtag = parse_sentence(sentence, wordlist)\n",
    "    list_40000.append(clean_hashtag)\n",
    "\n",
    "stop = time.default_timer()\n",
    "print('Time to run step 4: ', stop - start)   \n",
    "\n",
    "list_last = []\n",
    "for i in range(40000,49829):\n",
    "    sentence = hashtag_df[\"Hashtag\"][i]\n",
    "    clean_hashtag = parse_sentence(sentence, wordlist)\n",
    "    list_last.append(clean_hashtag)\n",
    "\n",
    "# Caculate program-run time   \n",
    "stop = time.default_timer()\n",
    "\n",
    "print('Time to run: ', stop - start)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create big dataframe with all hashtag lists\n",
    "df_1 = pd.DataFrame(list_10000)\n",
    "df_2 = pd.DataFrame(list_20000)\n",
    "df_3 = pd.DataFrame(list_30000)\n",
    "df_4 = pd.DataFrame(list_40000)\n",
    "df_5 = pd.DataFrame(list_last)\n",
    "df_6 = pd.concat([df_1, df_2, df_3, df_4, df_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of all hashtags list\n",
    "hashtag_total_list = df_6[0].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hashtag Sentiment Analysis using English Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text) :\n",
    "    \"\"\"\n",
    "    Define a function to get sentiment of hashtags.\n",
    "    We look at every word in the hashtag and see if it is mentioned in files with positive and negative words.\n",
    "    The functions return the total score which is the positive score minus the negative score.\n",
    "    For example : \"Trump bad crazy \" returns score of -2 because there are 2 negative words in the hashtag.\n",
    "    \"\"\"\n",
    "    raw_words = text.split(\" \")\n",
    "    #print(text)\n",
    "    with open(\"positive-words.txt\") as file_positive:\n",
    "        positive_words = [line.strip() for line in file_positive]\n",
    "\n",
    "    with open(\"negative-words.txt\") as file_negative:\n",
    "        negative_words = [line.strip() for line in file_negative]\n",
    "\n",
    "    positive_score = len([word for word in raw_words if word in positive_words])\n",
    "    negative_score = len([word for word in raw_words if word in negative_words])\n",
    "    #print(\"positive score: \",positive_score)\n",
    "    #print(\"negative_score: \", negative_score)\n",
    "    total_score = positive_score - negative_score\n",
    "    #print(\"total_score: \", total_score)\n",
    "    #print\n",
    "    \n",
    "    return total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the list of hashtags in the sentiment score function and create a score list\n",
    "sentiment_list = []\n",
    "for i in range(0,len(hashtag_total_list)):\n",
    "    text = hashtag_total_list[i]\n",
    "    sentiment_score = sentiment(text)\n",
    "    sentiment_list.append(sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>trump</td>\n",
       "      <td>57406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>never trump</td>\n",
       "      <td>21275</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>maga</td>\n",
       "      <td>18935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>im with her</td>\n",
       "      <td>17932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>never hillary</td>\n",
       "      <td>14662</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>hillary</td>\n",
       "      <td>13835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>hillary clinton</td>\n",
       "      <td>13430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>trump pence 16</td>\n",
       "      <td>13362</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>donald trump</td>\n",
       "      <td>12344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>crooked hillary</td>\n",
       "      <td>11414</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            hashtag  count  sentiment\n",
       "0            trump   57406          0\n",
       "1      never trump   21275         -1\n",
       "2             maga   18935          0\n",
       "3      im with her   17932          0\n",
       "4    never hillary   14662         -1\n",
       "5          hillary   13835          0\n",
       "6  hillary clinton   13430          0\n",
       "7   trump pence 16   13362          0\n",
       "8     donald trump   12344          0\n",
       "9  crooked hillary   11414         -1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create final DataFrame and save to excel\n",
    "final_df = pd.DataFrame(columns = [\"hashtag\", \"count\", \"sentiment\"])\n",
    "final_df[\"hashtag\"]=hashtag_total_list\n",
    "final_df[\"count\"]=hashtag_raw_count\n",
    "final_df[\"sentiment\"]=sentiment_list\n",
    "final_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_excel(\"Hashtag_df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
